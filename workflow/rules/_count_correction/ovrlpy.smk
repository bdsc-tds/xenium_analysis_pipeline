#######################################
#              Functions              #
#######################################

def get_input2_or_params4runOvrlpy(wildcards, for_input: bool = True) -> str:
    prefix: str = f'{config["output_path"]}/segmentation'
    ret: str = ""

    if wildcards.compact_segmentation_id == "10x_0um":
        ret = os.path.join(
            prefix,
            f"10x_0um/{wildcards.sample_id}/normalised_results",
        )

        if not for_input:
            ret = normalise_path(
                ret,
                candidate_paths=("outs",),
                pat_anchor_file=r"transcripts\.parquet",
                pat_flags=re.IGNORECASE,
                return_dir=False,
                check_exist=False
            )
    elif wildcards.compact_segmentation_id == "proseg":
        ret = os.path.join(
            prefix,
            f'proseg/{wildcards.sample_id}/raw_results/transcript-metadata.csv.gz'
        )
    else:
        raise RuntimeError(f"Error! Cannot run Ovrlpy on samples generated by unknown segmentation method: {wildcards.compact_segmentation_id}.")

    return ret


#######################################
#                Rules                #
#######################################

rule runOvrlpy:
    input:
        get_input2_or_params4runOvrlpy
    output:
        signal_integrity=protected(f'{config["output_path"]}/count_correction/{wildcards.compact_segmentation_id}/{wildcards.sample_id}/ovrlpy/signal_integrity.parquet'),
        signal_strength=protected(f'{config["output_path"]}/count_correction/{wildcards.compact_segmentation_id}/{wildcards.sample_id}/ovrlpy/signal_strength.parquet'),
        transcript_info=protected(f'{config["output_path"]}/count_correction/{wildcards.compact_segmentation_id}/{wildcards.sample_id}/ovrlpy/transcript_info.parquet')
    params:
        input_transcripts=lambda wildcards: get_input2_or_params4runOvrlpy(
            wildcards,
            for_input=False,
        ),
        proseg_format=lambda wildcards: '--proseg_format' if wildcards.compact_segmentation_id == 'proseg' else ''
    log:
        f'{config["output_path"]}/count_correction/{wildcards.compact_segmentation_id}/{wildcards.sample_id}/ovrlpy/logs/runOvrlpy.log'
    wildcard_constraints:
        compact_segmentation_id=r"10x_0um|proseg"
    container:
        config["containers"]["r"]
    conda:
        "../../envs/general.yml"
    resources:
        mem_mb=lambda wildcards, attempt: min(
            get_size(
                get_input2_or_params4runOvrlpy(
                    wildcards,
                    for_input=False
                )
            ) * 1e-6 * attempt**3 * 100,
            1024000
        )
    shell:
        "python workflow/scripts/_count_correction/ovrlpy_sample.py "
        "--sample_transcripts_path {params.input_transcripts} "
        "--out_file_signal_integrity {output.signal_integrity} "
        "--out_file_signal_strength {output.signal_strength} "
        "--out_file_transcript_info {output.transcript_info} "
        "{params.proseg_format} "
        "-l {log}"


rule getCorrectedCountsFromOvrlpy:
    input:
        transcripts=get_input2_or_params4runOvrlpy,
        signal_integrity=f'{config["output_path"]}/count_correction/{wildcards.compact_segmentation_id}/{wildcards.sample_id}/ovrlpy/signal_integrity.parquet',
        transcript_info=f'{config["output_path"]}/count_correction/{wildcards.compact_segmentation_id}/{wildcards.sample_id}/ovrlpy/transcript_info.parquet'
    output:
        corrected_counts=protected(f'{config["output_path"]}/count_correction/{wildcards.compact_segmentation_id}/{wildcards.sample_id}/ovrlpy/corrected_counts.h5'),
        cells_mean_integrity=protected(f'{config["output_path"]}/count_correction/{wildcards.compact_segmentation_id}/{wildcards.sample_id}/ovrlpy/cells_mean_integrity.parquet')
    params:
        input_transcripts=lambda wildcards: get_input2_or_params4runOvrlpy(
            wildcards,
            for_input=False,
        ),
        signal_integrity_threshold=get_dict_value(
            config,
            "count_correction",
            "ovrlpy",
            "signal_integrity_threshold",
            replace_none=0.5,
        ),
        proseg_format=lambda wildcards: '--proseg_format' if wildcards.compact_segmentation_id == 'proseg' else ''
    log:
        f'{config["output_path"]}/count_correction/{wildcards.compact_segmentation_id}/{wildcards.sample_id}/ovrlpy/logs/getCorrectedCountsFromOvrlpy.log'
    wildcard_constraints:
        compact_segmentation_id=r"10x_0um|proseg"
    container:
        config["containers"]["r"]
    conda:
        "../../envs/general.yml"
    resources:
        mem_mb=lambda wildcards, attempt: min(
            get_size(
                get_input2_or_params4runOvrlpy(
                    wildcards,
                    for_input=False
                )
            ) * 1e-6 * attempt * 50,
            512000
        )
    shell:
        "python workflow/scripts/_count_correction/ovrlpy_sample_correction.py "
        "--sample_transcripts_path {params.input_transcripts} "
        "--sample_signal_integrity {input.signal_integrity} "
        "--sample_transcript_info {input.transcript_info} "
        "--out_file_corrected_counts {output.corrected_counts} "
        "--out_file_cells_mean_integrity {output.cells_mean_integrity} "
        "--signal_integrity_threshold {params.signal_integrity_threshold} "
        "{params.proseg_format} "
        "-l {log}"
