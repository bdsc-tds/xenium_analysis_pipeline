from typing import Any
import os
import shutil
import json
include: "scripts/utils/config_utils.py"
include: "scripts/utils/raw_data_utils.py"
include: "scripts/utils/run_time_utils.py"

# Ensure that only one configuration file is used.
if len(workflow.configfiles) > 1:
    raise RuntimeError(f"Error! At most one configuration file is allowed to be passed via command line options, but {len(workflow.configfiles)} are detected.")
elif len(workflow.configfiles) == 0:
    configfile: 'config/config.yml'
assert len(workflow.configfiles) == 1

process_config(
    config,
    root_path=os.path.dirname(
        os.path.normpath(
            os.path.abspath(
                workflow.configfiles[0]
            )
        )
    )
)


#######################################
#             Local rules             #
#######################################

localrules: all


#######################################
#              Wildcards              #
#######################################

import config_constants as cc


"""
Explanation of wildcards:
- condition_id: The name of a condition to be processed with a format of "condition".
- gene_panel_id: The name of a gene panel to be processed with a format of "condition/gene_panel".
- sample_id: The name of an sample to be processed with a format of "condition/gene_panel/donor/sample".
- wrap_gene_panel_id: The name of a gene panel whose samples to be wrapped with a format of "condition-gene_panel".
- wrap_sample_id: The name of an sample to be wrapped with a format of "condition-gene_panel-donor-sample".
- geo_sub_sample_id: The name of a sample to be used for GEO submission with a format of "condition_gene_panel_donor_sample".
- compact_segmentation_id: The name of a segmentation method to only be used in segementation tasks.
- segmentation_id: The name of a segmentation method to be used in the tasks downstream to the segmentation, except for count correction.
- coexpression_id: The name of a coexpression method and target counts to be used in a format of "method_counts".
- normalisation_id: The name of a normalisation method to be used.
- annotation_id: The name of cell-type annotation to be used in a format "approach/reference_name/method/level/mode". E.g., "reference_based/matched_reference/rctd/Level3/single_cell".
- count_correction_id: The name of a count correction method to be used after segmentation.
- segmentation_id4ovrlpy: The name of segmentation methods to be used in transcripts processing when running Ovrlpy.
- doublet_id: The name of a doublet finding method to be used.
"""

CONDITION_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_CONDITIONS_NAME,
)
GENE_PANEL_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_GENE_PANELS_NAME,
)
SAMPLE_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_SAMPLES_NAME,
)
WRAP_GENE_PANEL_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_WRAP_GENE_PANELS_NAME,
)
WRAP_SAMPLE_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_WRAP_SAMPLES_NAME,
)
GEO_SUB_SAMPLE_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_GEO_SUB_SAMPLES_NAME,
)
COMPACT_SEGMENTATION_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_COMPACT_SEGMENTATION_NAME,
)
SEGMENTATION_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_SEGMENTATION_NAME,
)
COEXPRESSION_ID = uniquify_elements_in_list(
    *[
        i
        for i in get_dict_value(
            config,
            cc.WILDCARDS_NAME,
            cc.WILDCARDS_COEXPRESSION_NAME,
        ).values()
    ]
)
NORMALISATION_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_SEURAT_NORM_NAME,
)
ANNOTATION_ID = uniquify_elements_in_list(
    *[
        i
        for i in get_dict_value(
            config,
            cc.WILDCARDS_NAME,
            cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
        ).values()
    ]
)
COUNT_CORRECTION_ID=get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_COUNT_CORRECTION_NAME,
)
SEGMENTATION_ID4OVRLPY=get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_SEGMENTATION4OVRLPY_NAME,
)
DOUBLET_ID=get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_DOUBLET_FINDING_NAME,
)

wildcard_constraints:
    condition_id='|'.join([re.escape(i) for i in CONDITION_ID]),
    gene_panel_id='|'.join([re.escape(i) for i in GENE_PANEL_ID]),
    sample_id='|'.join([re.escape(i) for i in SAMPLE_ID]),
    wrap_gene_panel_id='|'.join([re.escape(i) for i in WRAP_GENE_PANEL_ID]),
    wrap_sample_id='|'.join([re.escape(i) for i in WRAP_SAMPLE_ID]),
    geo_sub_sample_id='|'.join([re.escape(i) for i in GEO_SUB_SAMPLE_ID]),
    compact_segmentation_id='|'.join([re.escape(i) for i in COMPACT_SEGMENTATION_ID]),
    segmentation_id='|'.join([re.escape(i) for i in SEGMENTATION_ID]),
    coexpression_id='|'.join([re.escape(i) for i in COEXPRESSION_ID]),
    normalisation_id='|'.join([re.escape(i) for i in NORMALISATION_ID]),
    annotation_id='|'.join([re.escape(i) for i in ANNOTATION_ID]),
    count_correction_id="|".join([re.escape(i) for i in COUNT_CORRECTION_ID]),
    segmentation_id4ovrlpy="|".join([re.escape(i) for i in SEGMENTATION_ID4OVRLPY]),
    doublet_id="|".join([re.escape(i) for i in DOUBLET_ID]),


########################################
#           Predefined rules           #
########################################

include: 'rules/reprocess_raw_data.smk'
include: 'rules/segmentation.smk'
include: 'rules/count_correction.smk'
include: 'rules/standard_seurat_analysis.smk'
include: 'rules/joint_scanpy_analysis.smk'
include: 'rules/coexpression.smk'
include: 'rules/neighborhood_analysis.smk'
include: 'rules/cell_type_annotation.smk'
include: 'rules/segmentation_qc.smk'
include: 'rules/doublet_finding.smk'
include: 'rules/data_wrapping.smk'
include: 'rules/geo_sub.smk'


#######################################
#              Functions              #
#######################################

def get_output4reports(
    run_cell_type_annotation: bool,
    run_count_correction: bool,
) -> list[str]:
    prefix: str = f'{config["output_path"]}/reports'
    ret: list[str] = []

    # Reports from standard Seurat analysis.
    ret.extend(
        [
            os.path.join(
                prefix,
                i,
                j,
                k,
                "standard_seurat_analysis.html",
            )
            for i in SEGMENTATION_ID
            for j in SAMPLE_ID
            for k in NORMALISATION_ID
        ]
    )

    # Reports from segmentation QC.

    ## Reports from RCTD results, if RCTD is used for annotation.
    ## Make sure that `run_cell_type_annotation` has higher priority than `_create_dummy_table`.
    ## If `run_cell_type_annotation` is True, then `_create_dummy_table` must be False.
    if run_cell_type_annotation and get_dict_value(
        config,
        "segmentation",
        "_qc",
        "_create_dummy_table",
        replace_none=False,
    ):
        raise RuntimeError("Error! If annotation is to be generated, then dummy tables must not be created. Please set '_create_dummy_table' to False.")

    if (run_cell_type_annotation or get_dict_value(
        config,
        "segmentation",
        "_qc",
        "_create_dummy_table",
        replace_none=False,
    )) and any(
        False if re.match(
            r".+/rctd_.+",
            i,
            flags=re.IGNORECASE,
        ) is None else True
        for i in ANNOTATION_ID
    ):
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    "segmentation_qc_rctd.html",
                )
                for i in GENE_PANEL_ID
            ]
        )
    else:
        print(
            "No reports for segmentation QC will be generated, as annotation results from RCTD is not available.",
        )

    # Reports from standard Seurat analysis after count correction.
    if run_count_correction:

        # Results from Ovrlpy, if it is specified.
        if "ovrlpy" in COUNT_CORRECTION_ID:
            ret.extend(
                [
                    os.path.join(
                        prefix,
                        i,
                        j,
                        "ovrlpy",
                        f'signal_integrity_threshold={get_dict_value(
                            config,
                            "count_correction",
                            "ovrlpy",
                            "signal_integrity_threshold",
                        )}',
                        k,
                        "standard_seurat_analysis.html",
                    )
                    for i in SEGMENTATION_ID
                    for j in SAMPLE_ID
                    for k in NORMALISATION_ID
                ]
            )

        # Results from `resolvi_unsupervised`, if it is specified.
        if "resolvi_unsupervised" in COUNT_CORRECTION_ID:
            ret.extend(
                [
                    os.path.join(
                        prefix,
                        i,
                        j,
                        "resolvi_unsupervised",
                        f'mixture_k={get_dict_value(
                            config,
                            "count_correction",
                            "resolvi",
                            "train",
                            "mixture_k",
                        )}',
                        f'num_samples={get_dict_value(
                            config,
                            "count_correction",
                            "resolvi",
                            "predict",
                            "num_samples",
                        )}',
                        k,
                        "standard_seurat_analysis.html",
                    )
                    for i in SEGMENTATION_ID
                    for j in SAMPLE_ID
                    for k in NORMALISATION_ID
                ]
            )

        if run_cell_type_annotation:

            samples_by_conditions: dict[str, list[str]] = get_dict_value(
                config,
                "experiments",
                cc.EXPERIMENTS_COLLECTIONS_NAME,
                cc.EXPERIMENTS_COLLECTIONS_CONDITIONS_NAME,
            )

            # Results from `resolvi_supervised`, if it is specified, and cell tyep annotation is configured to run.
            if "resolvi_supervised" in COUNT_CORRECTION_ID:
                if run_cell_type_annotation:
                    annotations_by_conditions: dict[str, list[str]] = get_dict_value(
                        config,
                        cc.WILDCARDS_NAME,
                        cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
                    )

                    samples_annotations: list[tuple[str, str]] = cross_values_by_key(
                        samples_by_conditions,
                        annotations_by_conditions,
                    )

                    ret.extend(
                        [
                            os.path.join(
                                prefix,
                                i,
                                j[0],
                                k,
                                j[1],
                                "resolvi_supervised",
                                f'mixture_k={get_dict_value(
                                    config,
                                    "count_correction",
                                    "resolvi",
                                    "train",
                                    "mixture_k",
                                )}',
                                f'num_samples={get_dict_value(
                                    config,
                                    "count_correction",
                                    "resolvi",
                                    "predict",
                                    "num_samples",
                                )}',
                                k,
                                "standard_seurat_analysis.html",
                            )
                            for i in SEGMENTATION_ID
                            for j in samples_annotations
                            for k in NORMALISATION_ID
                        ]
                    )
                else:
                    print(
                        'No results from count correction method "resolvi_supervised" will be generated even though it is configured to run, as annotation isn\'t.',
                    )
            
            # Results from `split_*`, if they are specified.
            split_methods: list[str] = [
                i
                for i in COUNT_CORRECTION_ID
                if re.match(
                    r"^split_.+$",
                    i,
                    flags=re.IGNORECASE,
                ) is not None
            ]

            if len(split_methods) > 0:
                if "split_fully_purified" not in split_methods:
                    raise RuntimeError("Error! If any method from 'split_*' is specified, then 'split_fully_purified' must be specified as well.")

                if run_cell_type_annotation and any(
                    False if re.match(
                        r".+/rctd_.+",
                        i,
                        flags=re.IGNORECASE,
                    ) is None else True
                    for i in ANNOTATION_ID
                ):
                    annotations_by_conditions: dict[str, list[str]] = {
                        cond: [
                            i
                            for i in anno
                            if re.match(
                                r".+/rctd_.+",
                                i,
                                flags=re.IGNORECASE,
                            ) is not None
                        ]
                        for cond, anno in get_dict_value(
                            config,
                            cc.WILDCARDS_NAME,
                            cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
                        ).items()
                    }

                    samples_annotations: list[tuple[str, str]] = cross_values_by_key(
                        samples_by_conditions,
                        annotations_by_conditions,
                    )

                    ret.extend(
                        [
                            os.path.join(
                                prefix,
                                i,
                                j[0],
                                k,
                                j[1],
                                l,
                                k,
                                "standard_seurat_analysis.html",
                            )
                            for i in SEGMENTATION_ID
                            for j in samples_annotations
                            for k in NORMALISATION_ID
                            for l in split_methods
                        ]
                    )
                else:
                    print(
                        f'No results from count correction methods {",".join(split_methods)} will be generated even though they are configured to run, as annotation using RCTD isn\'t.',
                    )

    return ret


def get_output4cleanup() -> list[str]:
    ret: list[str] = []

    # Get the path to the raw data, and save it if it is reprocessed.
    for i in SAMPLE_ID:
        use_raw_data, _ret = get_raw_data_dir(i)
        if not use_raw_data:
            ret.append(
                os.path.join(
                    _ret,
                    "_auxiliary_files.tar",
                )
            )

    # Get the path to the normalised results from all segmentation methods.
    seg_prefix: str = f'{config["output_path"]}/segmentation'
    ret.extend(
        [
            os.path.join(
                seg_prefix,
                i,
                j,
                "normalised_results",
                "_auxiliary_files.tar",
            )
            for i in COMPACT_SEGMENTATION_ID
            for j in SAMPLE_ID
        ]
    )

    # Clean up the Segger results.
    if "segger" in COMPACT_SEGMENTATION_ID:

        # Get the path to the preprocessed data from Segger.
        segger_prefix: str = f'{config["output_path"]}/segmentation/segger'
        ret.extend(
            [
                os.path.join(
                    segger_prefix,
                    i,
                    "preprocessed_data",
                    "tiles.tgz",
                )
                for i in SAMPLE_ID
            ]
        )

    return ret


def get_output4coexpression() -> list[str]:
    prefix: str = f'{config["output_path"]}/coexpression'
    filenames: list[str] = ["coexpression.parquet", "positivity_rate.parquet"]

    samples_by_gene_panels: dict[str, list[str]] = get_dict_value(
        config,
        "experiments",
        cc.EXPERIMENTS_COLLECTIONS_NAME,
        cc.EXPERIMENTS_COLLECTIONS_GENE_PANELS_NAME,
    )

    coexpression_by_gene_panels: dict[str, list[str]] = get_dict_value(
        config,
        cc.WILDCARDS_NAME,
        cc.WILDCARDS_COEXPRESSION_NAME,
    )

    samples_coexpression: list[tuple[str, str]] = cross_values_by_key(
        samples_by_gene_panels,
        coexpression_by_gene_panels,
    )

    return [
        os.path.join(
            prefix,
            i,
            j[0],
            j[1],
            k,
        )
        for i in SEGMENTATION_ID
        for j in samples_coexpression
        for k in filenames
    ]


def get_output4cell_type_annotation() -> list[str]:
    prefix: str = f'{config["output_path"]}/cell_type_annotation'
    filenames: list[str] = ["output.rds", "labels.parquet", "scores.parquet"]

    samples_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        "experiments",
        cc.EXPERIMENTS_COLLECTIONS_NAME,
        cc.EXPERIMENTS_COLLECTIONS_CONDITIONS_NAME,
    )

    annotations_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        cc.WILDCARDS_NAME,
        cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
    )

    samples_annotations: list[tuple[str, str]] = cross_values_by_key(
        samples_by_conditions,
        annotations_by_conditions,
    )

    return [
        os.path.join(
            prefix,
            i,
            j[0],
            k,
            j[1],
            m,
        )
        for i in SEGMENTATION_ID
        for j in samples_annotations
        for k in NORMALISATION_ID
        for m in filenames
    ]


def get_output4joint_analysis() -> list[str] | None:
    methods: list[str] = get_dict_value(
        config,
        "joint_scanpy_analysis",
        "methods",
    )

    if len(methods) == 0:
        print("No results from joint analysis will be generated.")
        return None
    
    joint_levels: list[str] = []
    if "condition_wise" in methods:
        joint_levels.extend(CONDITION_ID)
    if "gene_panel_wise" in methods:
        joint_levels.extend(GENE_PANEL_ID)

    prefix: str = f'{config["output_path"]}/joint_scanpy_analysis'

    return [
        os.path.join(
            prefix,
            i,
            j,
            "umap.parquet",
        )
        for i in SEGMENTATION_ID
        for j in joint_levels
    ]


def get_output4neighbirhood_analysis() -> list[str]:
    prefix: str = f'{config["output_path"]}/neighborhood_analysis'
    filenames: list[str] = [
        "spatial_neighborhood_scores.parquet",
        "transcriptomic_neighborhood_scores.parquet",
    ]

    samples_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        "experiments",
        cc.EXPERIMENTS_COLLECTIONS_NAME,
        cc.EXPERIMENTS_COLLECTIONS_CONDITIONS_NAME,
    )

    annotations_by_conditions: dict[str, list[str]] = {
        cond: [
            i
            for i in anno
            if re.match(
                r".+/rctd_.+",
                i,
                flags=re.IGNORECASE,
            ) is not None
        ]
        for cond, anno in get_dict_value(
            config,
            cc.WILDCARDS_NAME,
            cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
        ).items()
    }

    samples_annotations: list[tuple[str, str]] = cross_values_by_key(
        samples_by_conditions,
        annotations_by_conditions,
    )

    return [
        os.path.join(
            prefix,
            i,
            j[0],
            k,
            j[1],
            l,
        )
        for i in SEGMENTATION_ID
        for j in samples_annotations
        for k in NORMALISATION_ID
        for l in filenames
    ]


def get_output4doublet_finding() -> list[str]:
    prefix: str = f'{config["output_path"]}/doublet_finding'
    filenames: list[str] = [
        "doublet_scores.parquet",
    ]

    samples_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        "experiments",
        cc.EXPERIMENTS_COLLECTIONS_NAME,
        cc.EXPERIMENTS_COLLECTIONS_CONDITIONS_NAME,
    )

    annotations_by_conditions: dict[str, list[str]] = {
        cond: [
            i
            for i in anno
            if re.match(
                r".+/rctd_.+",
                i,
                flags=re.IGNORECASE,
            ) is not None
        ]
        for cond, anno in get_dict_value(
            config,
            cc.WILDCARDS_NAME,
            cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
        ).items()
    }

    samples_annotations: list[tuple[str, str]] = cross_values_by_key(
        samples_by_conditions,
        annotations_by_conditions,
    )

    return [
        os.path.join(
            prefix,
            i,
            j[0],
            k,
            j[1],
            l,
            m,
        )
        for i in SEGMENTATION_ID
        for j in samples_annotations
        for k in NORMALISATION_ID
        for l in DOUBLET_ID
        for m in filenames
    ]


def get_output4count_correction(
    run_cell_type_annotation: bool,
) -> list[str]:
    if len(COUNT_CORRECTION_ID) == 0:
        raise RuntimeError("Error! No methods for count correction specified.")
    
    ret: list[str] = []

    prefix: str = f'{config["output_path"]}/count_correction'

    # Results from Ovrlpy, if it is specified.
    if "ovrlpy" in COUNT_CORRECTION_ID:
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    j,
                    "ovrlpy",
                    f'signal_integrity_threshold={get_dict_value(
                        config,
                        "count_correction",
                        "ovrlpy",
                        "signal_integrity_threshold",
                    )}',
                    "corrected_counts.h5",
                )
                for i in SEGMENTATION_ID
                for j in SAMPLE_ID
            ]
        )

    # Results from `resolvi_unsupervised`, if it is specified.
    if "resolvi_unsupervised" in COUNT_CORRECTION_ID:
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    j,
                    "resolvi_unsupervised",
                    f'mixture_k={get_dict_value(
                        config,
                        "count_correction",
                        "resolvi",
                        "train",
                        "mixture_k",
                    )}',
                    f'num_samples={get_dict_value(
                        config,
                        "count_correction",
                        "resolvi",
                        "predict",
                        "num_samples",
                    )}',
                    "corrected_counts.h5",
                )
                for i in SEGMENTATION_ID
                for j in SAMPLE_ID
            ]
        )

    samples_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        "experiments",
        cc.EXPERIMENTS_COLLECTIONS_NAME,
        cc.EXPERIMENTS_COLLECTIONS_CONDITIONS_NAME,
    )

    # Results from `resolvi_supervised`, if it is specified, and cell tyep annotation is configured to run.
    if "resolvi_supervised" in COUNT_CORRECTION_ID:
        if run_cell_type_annotation:
            annotations_by_conditions: dict[str, list[str]] = get_dict_value(
                config,
                cc.WILDCARDS_NAME,
                cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
            )

            samples_annotations: list[tuple[str, str]] = cross_values_by_key(
                samples_by_conditions,
                annotations_by_conditions,
            )

            ret.extend(
                [
                    os.path.join(
                        prefix,
                        i,
                        j[0],
                        k,
                        j[1],
                        "resolvi_supervised",
                        f'mixture_k={get_dict_value(
                            config,
                            "count_correction",
                            "resolvi",
                            "train",
                            "mixture_k",
                        )}',
                        f'num_samples={get_dict_value(
                            config,
                            "count_correction",
                            "resolvi",
                            "predict",
                            "num_samples",
                        )}',
                        "corrected_counts.h5",
                    )
                    for i in SEGMENTATION_ID
                    for j in samples_annotations
                    for k in NORMALISATION_ID
                ]
            )
        else:
            print(
                'No results from count correction method "resolvi_supervised" will be generated even though it is configured to run, as annotation isn\'t.',
            )

    # Results from `split_*`, if they are specified.
    split_methods: list[str] = [
        i
        for i in COUNT_CORRECTION_ID
        if re.match(
            r"^split_.+$",
            i,
            flags=re.IGNORECASE,
        ) is not None
    ]

    if len(split_methods) > 0:
        if "split_fully_purified" not in split_methods:
            raise RuntimeError("Error! If any method from 'split_*' is specified, then 'split_fully_purified' must be specified as well.")

        if run_cell_type_annotation and any(
            False if re.match(
                r".+/rctd_.+",
                i,
                flags=re.IGNORECASE,
            ) is None else True
            for i in ANNOTATION_ID
        ):
            annotations_by_conditions: dict[str, list[str]] = {
                cond: [
                    i
                    for i in anno
                    if re.match(
                        r".+/rctd_.+",
                        i,
                        flags=re.IGNORECASE,
                    ) is not None
                ]
                for cond, anno in get_dict_value(
                    config,
                    cc.WILDCARDS_NAME,
                    cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
                ).items()
            }

            samples_annotations: list[tuple[str, str]] = cross_values_by_key(
                samples_by_conditions,
                annotations_by_conditions,
            )

            ret.extend(
                [
                    os.path.join(
                        prefix,
                        i,
                        j[0],
                        k,
                        j[1],
                        l,
                        m,
                    )
                    for i in SEGMENTATION_ID
                    for j in samples_annotations
                    for k in NORMALISATION_ID
                    for l in split_methods
                    for m in ["corrected_counts.h5", "corrected_counts_metadata.parquet"]
                ]
            )
        else:
            print(
                f'No results from count correction methods {",".join(split_methods)} will be generated even though they are configured to run, as annotation using RCTD isn\'t.',
            )

    return ret


def get_output4post_count_correction_cell_type_annotation(
    run_cell_type_annotation: bool,
) -> list[str]:
    prefix: str = f'{config["output_path"]}/post_count_correction_cell_type_annotation'
    filenames: list[str] = ["output.rds", "labels.parquet", "scores.parquet"]

    ret: list[str] = []

    samples_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        "experiments",
        cc.EXPERIMENTS_COLLECTIONS_NAME,
        cc.EXPERIMENTS_COLLECTIONS_CONDITIONS_NAME,
    )

    annotations_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        cc.WILDCARDS_NAME,
        cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
    )

    samples_annotations: list[tuple[str, str]] = cross_values_by_key(
        samples_by_conditions,
        annotations_by_conditions,
    )

    # Results from Ovrlpy, if it is specified.
    if "ovrlpy" in COUNT_CORRECTION_ID:
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    j[0],
                    "ovrlpy",
                    f'signal_integrity_threshold={get_dict_value(
                        config,
                        "count_correction",
                        "ovrlpy",
                        "signal_integrity_threshold",
                    )}',
                    k,
                    j[1],
                    m,
                )
                for i in SEGMENTATION_ID
                for j in samples_annotations
                for k in NORMALISATION_ID
                for m in filenames
            ]
        )

    # Results from `resolvi_unsupervised`, if it is specified.
    if "resolvi_unsupervised" in COUNT_CORRECTION_ID:
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    j[0],
                    "resolvi_unsupervised",
                    f'mixture_k={get_dict_value(
                        config,
                        "count_correction",
                        "resolvi",
                        "train",
                        "mixture_k",
                    )}',
                    f'num_samples={get_dict_value(
                        config,
                        "count_correction",
                        "resolvi",
                        "predict",
                        "num_samples",
                    )}',
                    k,
                    j[1],
                    m,
                )
                for i in SEGMENTATION_ID
                for j in samples_annotations
                for k in NORMALISATION_ID
                for m in filenames
            ]
        )

    # Results from `resolvi_supervised`, if it is specified, and cell tyep annotation is configured to run.
    if "resolvi_supervised" in COUNT_CORRECTION_ID:
        if run_cell_type_annotation:
            ret.extend(
                [
                    os.path.join(
                        prefix,
                        i,
                        j[0],
                        k,
                        j[1],
                        "resolvi_supervised",
                        f'mixture_k={get_dict_value(
                            config,
                            "count_correction",
                            "resolvi",
                            "train",
                            "mixture_k",
                        )}',
                        f'num_samples={get_dict_value(
                            config,
                            "count_correction",
                            "resolvi",
                            "predict",
                            "num_samples",
                        )}',
                        k,
                        j[1],
                        l,
                    )
                    for i in SEGMENTATION_ID
                    for j in samples_annotations
                    for k in NORMALISATION_ID
                    for l in filenames
                ]
            )
        else:
            print(
                'No cell type annotation results from count correction method "resolvi_supervised" will be generated even though it is configured to run, as annotation isn\'t.',
            )

    # Results from `split_*`, if they are specified.
    split_methods: list[str] = [
        i
        for i in COUNT_CORRECTION_ID
        if re.match(
            r"^split_.+$",
            i,
            flags=re.IGNORECASE,
        ) is not None
    ]

    if len(split_methods) > 0:
        if "split_fully_purified" not in split_methods:
            raise RuntimeError("Error! If any method from 'split_*' is specified, then 'split_fully_purified' must be specified as well.")

        if run_cell_type_annotation and any(
            False if re.match(
                r".+/rctd_.+",
                i,
                flags=re.IGNORECASE,
            ) is None else True
            for i in ANNOTATION_ID
        ):
            annotations_by_conditions_split: dict[str, list[str]] = {
                cond: [
                    i
                    for i in anno
                    if re.match(
                        r".+/rctd_.+",
                        i,
                        flags=re.IGNORECASE,
                    ) is not None
                ]
                for cond, anno in get_dict_value(
                    config,
                    cc.WILDCARDS_NAME,
                    cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
                ).items()
            }

            samples_annotations_split: list[tuple[str, str]] = cross_values_by_key(
                samples_by_conditions,
                annotations_by_conditions_split,
            )

            ret.extend(
                [
                    os.path.join(
                        prefix,
                        i,
                        j[0],
                        k,
                        j[1],
                        l,
                        k,
                        j[1],
                        m,
                    )
                    for i in SEGMENTATION_ID
                    for j in samples_annotations_split
                    for k in NORMALISATION_ID
                    for l in split_methods
                    for m in filenames
                ]
            )
        else:
            print(
                f'No cell type annotation results from count correction methods {",".join(split_methods)} will be generated even though they are configured to run, as annotation using RCTD isn\'t.',
            )

    return ret


def get_output4wrap(level: str) -> list[str]:
    if level == "gene_panel":
        return [
            f'{config["output_path"]}/wraps/raw_data/per_gene_panel/{i}.csv'
            for i in WRAP_GENE_PANEL_ID
        ]
    elif level == "sample":
        return [
            f'{config["output_path"]}/wraps/raw_data/per_sample/{i}.csv'
            for i in WRAP_SAMPLE_ID
        ]
    else:
        raise RuntimeError(f'Error! Unsupported level "{level}" for data wrapping. Please choose among: ["gene_panel", "sample"]')


def get_output4geo_sub() -> str:
    return f'{config["output_path"]}/geo_sub/geo_sub/MD5.txt'


def get_output4post_count_correction_neighbirhood_analysis() -> list[str]:
    prefix: str = f'{config["output_path"]}/post_count_correction_neighborhood_analysis'
    filenames: list[str] = [
        "spatial_neighborhood_scores.parquet",
        "transcriptomic_neighborhood_scores.parquet",
    ]

    ret: list[str] = []

    samples_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        "experiments",
        cc.EXPERIMENTS_COLLECTIONS_NAME,
        cc.EXPERIMENTS_COLLECTIONS_CONDITIONS_NAME,
    )

    annotations_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        cc.WILDCARDS_NAME,
        cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
    )

    samples_annotations: list[tuple[str, str]] = cross_values_by_key(
        samples_by_conditions,
        annotations_by_conditions,
    )

    # Results from Ovrlpy, if it is specified.
    if "ovrlpy" in COUNT_CORRECTION_ID:
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    j[0],
                    "ovrlpy",
                    f'signal_integrity_threshold={get_dict_value(
                        config,
                        "count_correction",
                        "ovrlpy",
                        "signal_integrity_threshold",
                    )}',
                    k,
                    j[1],
                    m,
                )
                for i in SEGMENTATION_ID
                for j in samples_annotations
                for k in NORMALISATION_ID
                for m in filenames
            ]
        )

    # Results from `resolvi_unsupervised`, if it is specified.
    if "resolvi_unsupervised" in COUNT_CORRECTION_ID:
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    j[0],
                    "resolvi_unsupervised",
                    f'mixture_k={get_dict_value(
                        config,
                        "count_correction",
                        "resolvi",
                        "train",
                        "mixture_k",
                    )}',
                    f'num_samples={get_dict_value(
                        config,
                        "count_correction",
                        "resolvi",
                        "predict",
                        "num_samples",
                    )}',
                    k,
                    j[1],
                    m,
                )
                for i in SEGMENTATION_ID
                for j in samples_annotations
                for k in NORMALISATION_ID
                for m in filenames
            ]
        )

    # Results from `resolvi_supervised`, if it is specified, and cell tyep annotation is configured to run.
    if "resolvi_supervised" in COUNT_CORRECTION_ID:
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    j[0],
                    k,
                    j[1],
                    "resolvi_supervised",
                    f'mixture_k={get_dict_value(
                        config,
                        "count_correction",
                        "resolvi",
                        "train",
                        "mixture_k",
                    )}',
                    f'num_samples={get_dict_value(
                        config,
                        "count_correction",
                        "resolvi",
                        "predict",
                        "num_samples",
                    )}',
                    k,
                    j[1],
                    l,
                )
                for i in SEGMENTATION_ID
                for j in samples_annotations
                for k in NORMALISATION_ID
                for l in filenames
            ]
        )

    # Results from `split_*`, if they are specified.
    split_methods: list[str] = [
        i
        for i in COUNT_CORRECTION_ID
        if re.match(
            r"^split_.+$",
            i,
            flags=re.IGNORECASE,
        ) is not None
    ]

    if len(split_methods) > 0:
        if "split_fully_purified" not in split_methods:
            raise RuntimeError("Error! If any method from 'split_*' is specified, then 'split_fully_purified' must be specified as well.")

        if any(
            False if re.match(
                r".+/rctd_.+",
                i,
                flags=re.IGNORECASE,
            ) is None else True
            for i in ANNOTATION_ID
        ):
            annotations_by_conditions_split: dict[str, list[str]] = {
                cond: [
                    i
                    for i in anno
                    if re.match(
                        r".+/rctd_.+",
                        i,
                        flags=re.IGNORECASE,
                    ) is not None
                ]
                for cond, anno in get_dict_value(
                    config,
                    cc.WILDCARDS_NAME,
                    cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
                ).items()
            }

            samples_annotations_split: list[tuple[str, str]] = cross_values_by_key(
                samples_by_conditions,
                annotations_by_conditions_split,
            )

            ret.extend(
                [
                    os.path.join(
                        prefix,
                        i,
                        j[0],
                        k,
                        j[1],
                        l,
                        k,
                        j[1],
                        m,
                    )
                    for i in SEGMENTATION_ID
                    for j in samples_annotations_split
                    for k in NORMALISATION_ID
                    for l in split_methods
                    for m in filenames
                ]
            )
        else:
            print(
                f'No neighborhood analysis results from count correction methods {",".join(split_methods)} will be generated even though they are configured to run, as cell type annotation using RCTD isn\'t.',
            )

    return ret


def get_input2all(
    wildcards,
    *,
    reports: bool = True,
    coexpression: bool = True,
    cell_type_annotation: bool = True,
    doublet_finding: bool = False,
    joint_analysis: bool = True,
    neighbirhood_analysis: bool = False,
    count_correction: bool = True,
    post_count_correction_cell_type_annotation: bool = True,
    post_count_correction_neighbirhood_analysis: bool = False,
    cleanup: bool = False,
    wrap: str | None = None,
    geo_sub: bool = False,
) -> list[str]:
    ret: list[str] = []

    if coexpression:
        ret.extend(get_output4coexpression())

    if cell_type_annotation:
        ret.extend(get_output4cell_type_annotation())

        if neighbirhood_analysis:
            ret.extend(get_output4neighbirhood_analysis())

        if doublet_finding:
            ret.extend(get_output4doublet_finding())
        
    if count_correction:
        ret.extend(get_output4count_correction(
            cell_type_annotation,
        ))

        if post_count_correction_cell_type_annotation:
            ret.extend(get_output4post_count_correction_cell_type_annotation(
                cell_type_annotation,
            ))

            if post_count_correction_neighbirhood_analysis:
                ret.extend(get_output4post_count_correction_neighbirhood_analysis())

    if reports:
        ret.extend(get_output4reports(
            cell_type_annotation,
            count_correction,
        ))

    if joint_analysis:
        res = get_output4joint_analysis()
        if res is not None and len(res) > 0:
            ret.extend(res)

    if cleanup:
        ret.extend(get_output4cleanup())

    if wrap is not None:
        ret.extend(get_output4wrap(wrap))
    
    if geo_sub:
        ret.append(get_output4geo_sub())

    return ret


#######################################
#                Rules                #
#######################################

rule all:
    input:
        lambda wildcards: get_input2all(
            wildcards,
            reports=True,
            coexpression=True,
            cell_type_annotation=True,
            doublet_finding=True,
            joint_analysis=True,
            neighbirhood_analysis=False,
            count_correction=True,
            post_count_correction_cell_type_annotation=True,
            post_count_correction_neighbirhood_analysis=False,
            cleanup=False,
            wrap=None,
            geo_sub=False,
        )
