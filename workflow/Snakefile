from typing import Any
import os
import shutil
import json
include: "scripts/utils/config_utils.py"
include: "scripts/utils/raw_data_utils.py"
include: "scripts/utils/run_time_utils.py"

# Ensure that only one configuration file is used.
if len(workflow.configfiles) > 1:
    raise RuntimeError(f"Error! At most one configuration file is allowed to be passed via command line options, but {len(workflow.configfiles)} are detected.")
elif len(workflow.configfiles) == 0:
    configfile: 'config/config.yml'
assert len(workflow.configfiles) == 1

process_config(
    config,
    root_path=os.path.dirname(
        os.path.normpath(
            os.path.abspath(
                workflow.configfiles[0]
            )
        )
    )
)


#######################################
#             Local rules             #
#######################################

localrules: all


#######################################
#              Wildcards              #
#######################################

import config_constants as cc


"""
Explanation of wildcards:
- condition_id: The name of a condition to be processed with a format of "condition".
- gene_panel_id: The name of a gene panel to be processed with a format of "condition/gene_panel".
- sample_id: The name of an sample to be processed with a format of "condition/gene_panel/donor/sample".
- compact_segmentation_id: The name of a segmentation method to only be used in segementation tasks.
- segmentation_id: The name of a segmentation method to be used in the tasks downstream to the segmentation, except for count correction.
- coexpression_id: The name of a coexpression method and target counts to be used in a format of "method_counts".
- normalisation_id: The name of a normalisation method to be used.
- annotation_id: The name of cell-type annotation to be used in a format "approach/reference_name/method/level/mode". E.g., "reference_based/matched_reference/rctd/Level3/single_cell".
- count_correction_id: The name of a count correction method to be used after segmentation.
"""

CONDITION_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_CONDITIONS_NAME,
)
GENE_PANEL_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_GENE_PANELS_NAME,
)
SAMPLE_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_SAMPLES_NAME,
)
COMPACT_SEGMENTATION_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_COMPACT_SEGMENTATION_NAME,
)
SEGMENTATION_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_SEGMENTATION_NAME,
)
COEXPRESSION_ID = uniquify_elements_in_list(
    *[
        i
        for i in get_dict_value(
            config,
            cc.WILDCARDS_NAME,
            cc.WILDCARDS_COEXPRESSION_NAME,
        ).values()
    ]
)
NORMALISATION_ID = get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_SEURAT_NORM_NAME,
)
ANNOTATION_ID = uniquify_elements_in_list(
    *[
        i
        for i in get_dict_value(
            config,
            cc.WILDCARDS_NAME,
            cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
        ).values()
    ]
)
COUNT_CORRECTION_ID=get_dict_value(
    config,
    cc.WILDCARDS_NAME,
    cc.WILDCARDS_COUNT_CORRECTION_NAME,
)

wildcard_constraints:
    condition_id='|'.join([re.escape(i) for i in CONDITION_ID]),
    gene_panel_id='|'.join([re.escape(i) for i in GENE_PANEL_ID]),
    sample_id='|'.join([re.escape(i) for i in SAMPLE_ID]),
    compact_segmentation_id='|'.join([re.escape(i) for i in COMPACT_SEGMENTATION_ID]),
    segmentation_id='|'.join([re.escape(i) for i in SEGMENTATION_ID]),
    coexpression_id='|'.join([re.escape(i) for i in COEXPRESSION_ID]),
    normalisation_id='|'.join([re.escape(i) for i in NORMALISATION_ID]),
    annotation_id='|'.join([re.escape(i) for i in ANNOTATION_ID]),
    count_correction_id="|".join([re.escape(i) for i in COUNT_CORRECTION_ID])


########################################
#           Predefined rules           #
########################################

include: 'rules/reprocess_raw_data.smk'
include: 'rules/segmentation.smk'
include: 'rules/count_correction.smk'
include: 'rules/standard_seurat_analysis.smk'
include: 'rules/coexpression.smk'
include: 'rules/cell_type_annotation.smk'
include: 'rules/segmentation_qc.smk'


#######################################
#              Functions              #
#######################################

def get_output4reports(
    run_cell_type_annotation: bool
) -> list[str]:
    prefix: str = f'{config["output_path"]}/reports'
    ret: list[str] = []

    # Reports from standard Seurat analysis.
    ret.extend(
        [
            os.path.join(
                prefix,
                i,
                j,
                k,
                "standard_seurat_analysis.html",
            )
            for i in SEGMENTATION_ID
            for j in SAMPLE_ID
            for k in NORMALISATION_ID
        ]
    )

    # Reports from segmentation QC.

    ## Reports from RCTD results, if RCTD is used for annotation.
    if run_cell_type_annotation and any(
        False if re.match(
            r"reference_based/.+/rctd_.+",
            i,
            flags=re.IGNORECASE,
        ) is None else True
        for i in ANNOTATION_ID
    ):
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    "segmentation_qc_reference_based_rctd.html",
                )
                for i in GENE_PANEL_ID
            ]
        )
    else:
        print(
            "No reports from reference based RCTD will be generated, as RCTD is not used for annotation.",
        )

    return ret


def get_output4cleanup() -> list[str]:
    ret: list[str] = []

    # Get the path to the raw data, and save it if it is reprocessed.
    for i in SAMPLE_ID:
        use_raw_data, _ret = get_raw_data_dir(i)
        if not use_raw_data:
            ret.append(
                os.path.join(
                    _ret,
                    "_auxiliary_files.tar",
                )
            )

    # Get the path to the normalised results from all segmentation methods.
    seg_prefix: str = f'{config["output_path"]}/segmentation'
    ret.extend(
        [
            os.path.join(
                seg_prefix,
                i,
                j,
                "normalised_results",
                "_auxiliary_files.tar",
            )
            for i in COMPACT_SEGMENTATION_ID
            for j in SAMPLE_ID
        ]
    )

    # Clean up the Segger results.
    if "segger" in COMPACT_SEGMENTATION_ID:

        # Get the path to the preprocessed data from Segger.
        segger_prefix: str = f'{config["output_path"]}/segmentation/segger'
        ret.extend(
            [
                os.path.join(
                    segger_prefix,
                    i,
                    "preprocessed_data",
                    "tiles.tgz",
                )
                for i in SAMPLE_ID
            ]
        )

    return ret


def get_output4coexpression() -> list[str]:
    prefix: str = f'{config["output_path"]}/coexpression'
    filenames: list[str] = ["coexpression.parquet", "positivity_rate.parquet"]

    samples_by_gene_panels: dict[str, list[str]] = get_dict_value(
        config,
        "experiments",
        cc.EXPERIMENTS_COLLECTIONS_NAME,
        cc.EXPERIMENTS_COLLECTIONS_GENE_PANELS_NAME,
    )

    coexpression_by_gene_panels: dict[str, list[str]] = get_dict_value(
        config,
        cc.WILDCARDS_NAME,
        cc.WILDCARDS_COEXPRESSION_NAME,
    )

    samples_coexpression: list[tuple[str, str]] = cross_values_by_key(
        samples_by_gene_panels,
        coexpression_by_gene_panels,
    )

    return [
        os.path.join(
            prefix,
            i,
            j[0],
            j[1],
            k,
        )
        for i in SEGMENTATION_ID
        for j in samples_coexpression
        for k in filenames
    ]


def get_output4cell_type_annotation() -> list[str]:
    prefix: str = f'{config["output_path"]}/cell_type_annotation'
    filenames: list[str] = ["output.rds", "labels.parquet", "scores.parquet"]

    samples_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        "experiments",
        cc.EXPERIMENTS_COLLECTIONS_NAME,
        cc.EXPERIMENTS_COLLECTIONS_CONDITIONS_NAME,
    )

    annotations_by_conditions: dict[str, list[str]] = get_dict_value(
        config,
        cc.WILDCARDS_NAME,
        cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
    )

    samples_annotations: list[tuple[str, str]] = cross_values_by_key(
        samples_by_conditions,
        annotations_by_conditions,
    )

    return [
        os.path.join(
            prefix,
            i,
            j[0],
            k,
            j[1],
            m,
        )
        for i in SEGMENTATION_ID
        for j in samples_annotations
        for k in NORMALISATION_ID
        for m in filenames
    ]


def get_output4count_correction(
    run_cell_type_annotation: bool,
) -> list[str]:
    if len(COUNT_CORRECTION_ID) == 0:
        raise RuntimeError("Error! No methods for count correction specified.")
    
    ret: list[str] = []

    prefix: str = f'{config["output_path"]}/count_correction'

    # Outputs from Ovrlpy, if it is specified.
    if "ovrlpy" in COUNT_CORRECTION_ID:
        valid_seg_methods: list[str] = [
            i
            for i in SEGMENTATION_ID
            if re.match(
                r"(^10x_\w*?_?0um$)|(^proseg_expected$)",
                i,
                flags=re.IGNORECASE,
            ) is not None
        ]

        if len(valid_seg_methods) > 0:
            ret.extend(
                [
                    os.path.join(
                        prefix,
                        i,
                        j,
                        "ovrlpy",
                        f'signal_integrity_threshold={get_dict_value(
                            config,
                            "count_correction",
                            "ovrlpy",
                            "signal_integrity_threshold",
                        )}',
                        k,
                    )
                    for i in valid_seg_methods
                    for j in SAMPLE_ID
                    for k in ["corrected_counts.h5", "cells_mean_integrity_filtered.parquet"]
                ]
            )

    # Results from `resolvi_unsupervised`, if it is specified.
    if "resolvi_unsupervised" in COUNT_CORRECTION_ID:
        ret.extend(
            [
                os.path.join(
                    prefix,
                    i,
                    j,
                    "resolvi_unsupervised",
                    k,
                )
                for i in SEGMENTATION_ID
                for j in SAMPLE_ID
                for k in ["corrected_counts.h5", "proportions.parquet"]
            ]
        )

    # Results from `resolvi_supervised`, if it is specified, and cell tyep annotation is configured to run.
    if "resolvi_supervised" in COUNT_CORRECTION_ID:
        if run_cell_type_annotation:
            samples_by_conditions: dict[str, list[str]] = get_dict_value(
                config,
                "experiments",
                cc.EXPERIMENTS_COLLECTIONS_NAME,
                cc.EXPERIMENTS_COLLECTIONS_CONDITIONS_NAME,
            )

            annotations_by_conditions: dict[str, list[str]] = get_dict_value(
                config,
                cc.WILDCARDS_NAME,
                cc.WILDCARDS_CELL_TYPE_ANNOTATION_NAME,
            )

            samples_annotations: list[tuple[str, str]] = cross_values_by_key(
                samples_by_conditions,
                annotations_by_conditions,
            )

            ret.extend(
                [
                    os.path.join(
                        prefix,
                        i,
                        j[0],
                        k,
                        j[1],
                        "resolvi_supervised",
                        l,
                    )
                    for i in SEGMENTATION_ID
                    for j in samples_annotations
                    for k in NORMALISATION_ID
                    for l in ["corrected_counts.h5", "proportions.parquet"]
                ]
            )
        else:
            print(
                'No results from count correction method "resolvi_supervised" will be generated even though it is configured to run, as annotation isn\'t.',
            )

    return ret


def get_input2all(
    wildcards,
    *,
    reports: bool = True,
    coexpression: bool = True,
    cell_type_annotation: bool = True,
    count_correction: bool = True,
    cleanup: bool = False
) -> list[str]:
    ret: list[str] = []

    if coexpression:
        ret.extend(get_output4coexpression())

    if cell_type_annotation:
        ret.extend(get_output4cell_type_annotation())
    
    if count_correction:
        ret.extend(get_output4count_correction(
            cell_type_annotation,
        ))

    if reports:
        ret.extend(get_output4reports(
            cell_type_annotation,
        ))

    if cleanup:
        ret.extend(get_output4cleanup())
    
    return ret


#######################################
#                Rules                #
#######################################

rule all:
    input:
        lambda wildcards: get_input2all(
            wildcards,
            reports=True,
            coexpression=True,
            cell_type_annotation=True,
            count_correction=True,
            cleanup=False,
        )
